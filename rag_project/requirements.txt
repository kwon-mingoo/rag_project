#[GPU 가속] RTX 5090용 Llama-cpp-python (CUDA 12.4)

--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

#1. 핵심 라이브러리 (버전 호환성 유지)

numpy<2.0

#2. LangChain 프레임워크

langchain==0.3.0
langchain-community==0.3.0
langchain-huggingface
langchain-text-splitters

#3. LLM 및 RAG 엔진

llama-cpp-python
pypdf
sentence-transformers
rank_bm25           # Hybrid Search(키워드 검색)용 라이브러리
# faiss-gpu  # (참고: 만약 pip로 안 깔리면 conda install faiss-gpu 권장)


#4. 평가(Evaluation)용 라이브러리

nltk
scikit-learn
rouge-score
